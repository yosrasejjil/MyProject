{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "## Explore the data\n",
    "\n",
    "df=pd.read_csv(\"dataSetFinal.csv\")\n",
    "df \n",
    "\n",
    "columns=df.columns\n",
    "columns\n",
    "\n",
    "## Checking data type\n",
    "\n",
    "\n",
    "df.dtypes\n",
    "\n",
    "df.shape\n",
    "# df.info \n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "## Data reduction\n",
    "\n",
    "columns_to_drop = ['cik', 'ticker', 'accessionNo', 'companyName', 'fy', 'fp', 'form', 'filed']\n",
    "\n",
    "# Drop the specified columns if they exist in the DataFrame\n",
    "df.drop(columns=[col for col in columns_to_drop if col in df.columns], inplace=True)\n",
    "\n",
    "df.shape \n",
    "\n",
    "## Duplicate values\n",
    "\n",
    "df.duplicated().sum()\n",
    "\n",
    "df= df.drop_duplicates()\n",
    "df.duplicated().sum()\n",
    "\n",
    "## Checking if there is null values\n",
    "\n",
    "\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_melt = df.isnull().melt(var_name='variable', value_name='missing')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(\n",
    "    data=df_melt,\n",
    "    y='variable',\n",
    "    hue='missing',\n",
    "    multiple='stack',\n",
    "    palette={True: 'lightcoral', False: 'lightblue'}\n",
    ")\n",
    "\n",
    "plt.title('Missing Data Visualization')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Variable')\n",
    "plt.show()\n",
    "\n",
    "# ## dendogramme\n",
    "# # Create a boolean DataFrame showing where values are missing\n",
    "# missing_data = df.isnull()\n",
    "\n",
    "# # Perform hierarchical clustering using linkage\n",
    "# Z = linkage(missing_data.T, method='ward')\n",
    "\n",
    "# # Plotting the dendrogram\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# dendrogram(Z, labels=missing_data.columns, leaf_rotation=90)\n",
    "\n",
    "# plt.title('Missing Data Visualization 2')\n",
    "# plt.xlabel('Variables')\n",
    "# plt.ylabel('Distance')\n",
    "# plt.show()\n",
    "\n",
    "### I decided to delete columns with a lot missing data (55% )\n",
    "\n",
    "\n",
    "# using a 55% threshold is a standard approach for dropping columns, always validate against your problem, domain, and dataset\n",
    "\n",
    "# Calculate the percentage of missing values for each column\n",
    "missing_percentages = df.isnull().mean() * 100\n",
    "\n",
    "# Filter and sort columns with more than 55% missing values\n",
    "columns_to_drop = missing_percentages[missing_percentages > 55].sort_values(ascending=False)\n",
    "columns_to_drop1 = missing_percentages[missing_percentages > 55].index.tolist()\n",
    "\n",
    "# Print the columns and their corresponding percentages\n",
    "print(\"Columns with more than 55% missing values (in descending order):\")\n",
    "for column, percentage in columns_to_drop.items():\n",
    "    print(f\"{column}: {percentage:.2f}%\")\n",
    "\n",
    "\n",
    "#columns_to_drop = ['Noncurrent_Liabilities','ShortTerm_Debt','Nonoperating_Income','GrossProfit','Intangible_Assets','Current_Other_Assets','Noncurrent_Assets']\n",
    "\n",
    "df.drop(columns=[col for col in columns_to_drop1 if col in df.columns], inplace=True)\n",
    "df.shape \n",
    "\n",
    "## Distribution between bankrupt and normal company \n",
    "\n",
    "X = df.drop(['is_bankrupt'], axis=1)\n",
    "y = df['is_bankrupt']\n",
    "y.value_counts()\n",
    "\n",
    "sns.countplot(x='is_bankrupt', data=df , palette=['skyblue', 'lightcoral'])\n",
    "plt.title('Distribution of companies (successful vs is_bankrupt')\n",
    "plt.show()\n",
    "\n",
    "## Splitting data\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "### ** Separte the majority and minority **\n",
    "\n",
    "# Separating training data \n",
    "#minority\n",
    "X_train_bankrupted = X_train[y_train == 1]\n",
    "y_train_bankrupted = y_train[y_train == 1]\n",
    "#majority\n",
    "X_train_successful = X_train[y_train == 0]\n",
    "y_train_successful = y_train[y_train == 0]\n",
    "\n",
    "# Separating testing data\n",
    "#minority\n",
    "X_test_bankrupted = X_test[y_test == 1]\n",
    "y_test_bankrupted = y_test[y_test == 1]\n",
    "#majority\n",
    "X_test_successful = X_test[y_test == 0]\n",
    "y_test_successful = y_test[y_test == 0]\n",
    "\n",
    "\n",
    "### **for the majority i decided to drop columns with null values**\n",
    "\n",
    "# Dropping missing values from the training dataset\n",
    "X_train_successful = X_train_successful.dropna()\n",
    "y_train_successful = y_train_successful[X_train_successful.index]  # Aligning the target with features\n",
    "\n",
    "# Dropping missing values from the testing dataset\n",
    "X_test_successful = X_test_successful.dropna()\n",
    "y_test_successful = y_test_successful[X_test_successful.index]  # Aligning the target with features\n",
    "\n",
    "\n",
    "### **for the minority i decided to do data imputation**\n",
    "\n",
    "### Multiple Imputation with Chained Equations (MICE)\n",
    "\n",
    "# !pip install fancyimpute\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fancyimpute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Step 3: Visualize Missing Data for Bankrupted Cases (Initial State)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(X_train_bankrupted.isnull(), cbar=False, cmap='Reds')\n",
    "plt.title('Initial Missing Data in Bankrupted Cases (Red Indicates Missing)')\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Randomly fill missing data for bankrupted cases\n",
    "random_fill_bankrupted = X_train_bankrupted.apply(lambda col: col.fillna(np.random.choice(col.dropna())), axis=0)\n",
    "\n",
    "# Step 5: Apply MICE for Bankrupted Cases\n",
    "imputer_bankrupted = IterativeImputer(estimator=LinearRegression(), max_iter=10, random_state=0)\n",
    "imputed_train_bankrupted = imputer_bankrupted.fit_transform(random_fill_bankrupted)\n",
    "\n",
    "# Convert the result back to a DataFrame\n",
    "df_train_imputed_bankrupted = pd.DataFrame(imputed_train_bankrupted, columns=random_fill_bankrupted.columns)\n",
    "\n",
    "# Perform imputation on the test set for bankrupted cases\n",
    "imputed_test_bankrupted = imputer_bankrupted.transform(X_test_bankrupted)\n",
    "df_test_imputed_bankrupted = pd.DataFrame(imputed_test_bankrupted, columns=X_test_bankrupted.columns)\n",
    "\n",
    "# Step 6: Visualize Imputed Data for Bankrupted Cases (Final State)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df_train_imputed_bankrupted.isnull(), cbar=False, cmap='Reds')\n",
    "plt.title('Imputed Training Data for Bankrupted Cases (Red Indicates Remaining Missing)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## Concat the data again\n",
    "\n",
    "\n",
    "# Concatenate imputed features and target variable for the training set\n",
    "X_train = pd.concat([df_train_imputed_bankrupted, X_train_successful], axis=0)  \n",
    "y_train = pd.concat([y_train_bankrupted, y_train_successful], axis=0)  \n",
    "\n",
    "# Concatenate imputed features and target variable for the testing set\n",
    "X_test = pd.concat([df_test_imputed_bankrupted, X_test_successful], axis=0)  # Combine features\n",
    "y_test = pd.concat([y_test_bankrupted, y_test_successful], axis=0)  # Combine targets\n",
    "\n",
    "# Resetting index (optional but often useful)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(X_train.isnull().sum())\n",
    "\n",
    "# Set the size of the plot\n",
    "plt.figure(figsize=(20, 10))\n",
    "columns=df.columns\n",
    "# Loop through the columns and create subplots\n",
    "for i, column in enumerate(columns, 1):\n",
    "    plt.subplot(5, 4, i)\n",
    "    sns.boxplot(y=df[column])\n",
    "    plt.title(column)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Set the size of the overall plot\n",
    "plt.figure(figsize=(20, 5))  # Adjust height to fit one row nicely\n",
    "\n",
    "columns = ['Stockholder_Equity', 'Retained_Earnings', 'Working_capital', 'Liabilities', 'LongTerm_Debt']\n",
    "rows, cols = 2, 3  # 1 row, 5 columns\n",
    "\n",
    "# Set y-axis limit\n",
    "y_max = 1500\n",
    "\n",
    "# Create subplots\n",
    "for i, column in enumerate(columns):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    sns.histplot(df[column], kde=True)\n",
    "    plt.ylim(0, y_max)  # Set the y-axis (ordinate axis) limit\n",
    "    plt.title(f'Distribution of {column}')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Set the size of the overall plot\n",
    "plt.figure(figsize=(20, 5))  # Adjust height to fit one row nicely\n",
    "\n",
    "columns = ['Stockholder_Equity', 'Retained_Earnings', 'Working_capital', 'Liabilities', 'LongTerm_Debt']\n",
    "rows, cols = 1, 5  # 1 row, 5 columns\n",
    "\n",
    "# Set y-axis limit\n",
    "y_max = 1500\n",
    "\n",
    "# Create subplots\n",
    "for i, column in enumerate(columns):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    sns.histplot(df[column], kde=True)\n",
    "    plt.ylim(0, y_max)  # Set the y-axis (ordinate axis) limit\n",
    "    plt.title(f'Distribution of {column}')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### Normalization\n",
    "\n",
    "# Initialize the RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data (without re-fitting the scaler)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert the numpy arrays back to DataFrames with the same column names as X_train and X_test\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "# Optionally, if you want to reassign df to the scaled data (use X_train or X_test as required)\n",
    "X_train = X_train_scaled\n",
    "X_train = X_test_scaled\n",
    "\n",
    "# Display the first few rows of the scaled training data\n",
    "print(X_train.head())\n",
    "\n",
    "\n",
    "## features engineering **************************\n",
    "\n",
    "# Define a function to calculate all 19 financial ratios\n",
    "def calculate_ratios(df):\n",
    "    # R1: Current Ratio = Current Assets / Current Liabilities\n",
    "    df['R1'] = df['Current_Assets'] / df['Current_liabilities']\n",
    "\n",
    "    # R3: Debt to Equity Ratio = Liabilities / Stockholder Equity\n",
    "    df['R3'] = df['Liabilities'] / df['Stockholder_Equity']\n",
    "\n",
    "    # R4: Working Capital Ratio = Working Capital / Total Assets\n",
    "    df['R4'] = df['Working_capital'] / df['Assets']\n",
    "\n",
    "    # R5: Net Income Margin = Net Income / Revenues\n",
    "    df['R5'] = df['NetIncome'] / df['Revenues']\n",
    "\n",
    "    # R6: Return on Assets (ROA) = Net Income / Total Assets\n",
    "    df['R6'] = df['NetIncome'] / df['Assets']\n",
    "\n",
    "    # R7: Return on Equity (ROE) = Net Income / Stockholder Equity\n",
    "    df['R7'] = df['NetIncome'] / df['Stockholder_Equity']\n",
    "\n",
    "    # R8: Cash Ratio = Cash / Current Liabilities\n",
    "    df['R8'] = df['Cash'] / df['Current_liabilities']\n",
    "\n",
    "    # R9: Operating Cash Flow to Total Debt Ratio = Net Cash Operating Activities / Total Liabilities\n",
    "    df['R9'] = df['NetCash_OperatingActivities'] / df['Liabilities']\n",
    "\n",
    "    # R10: Interest Coverage Ratio = Earnings Before Interest and Taxes (EBIT) / Interest Expense\n",
    "    df['R10'] = df['Earning_Before_Interest_And_Taxes'] / df['InterestExpense']\n",
    "\n",
    "    # R12: Debt to Assets Ratio = Liabilities / Total Assets\n",
    "    df['R12'] = df['Liabilities'] / df['Assets']\n",
    "\n",
    "    # R13: Net Working Capital to Revenues = Working Capital / Revenues\n",
    "    df['R13'] = df['Working_capital'] / df['Revenues']\n",
    "\n",
    "    # R14: Retained Earnings to Assets Ratio = Retained Earnings / Total Assets\n",
    "    df['R14'] = df['Retained_Earnings'] / df['Assets']\n",
    "\n",
    "    # R16: Long-Term Debt to Total Capitalization = Long-Term Debt / (Long-Term Debt + Stockholder Equity)\n",
    "    df['R16'] = df['LongTerm_Debt'] / (df['LongTerm_Debt'] + df['Stockholder_Equity'])\n",
    "\n",
    "    # R17: Cash Flow to Sales Ratio = Net Cash Operating Activities / Revenues\n",
    "    df['R17'] = df['NetCash_OperatingActivities'] / df['Revenues']\n",
    "\n",
    "    # R18: Investing Cash Flow to Assets Ratio = Net Cash Investing Activities / Total Assets\n",
    "    df['R18'] = df['NetCash_InvestingActivities'] / df['Assets']\n",
    "\n",
    "    # R19: Financing Cash Flow to Total Debt Ratio = Net Cash Financing Activities / Total Liabilities\n",
    "    df['R19'] = df['NetCash_FinancingActivities'] / df['Liabilities']\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the ratio calculations to both X_train and X_test\n",
    "X_train = calculate_ratios(X_train)\n",
    "X_test = calculate_ratios(X_test)\n",
    "\n",
    "\n",
    "# Check for NaN values\n",
    "nan_values = X_train.isna().sum()\n",
    "print(\"NaN values in each column:\\n\", nan_values)\n",
    "\n",
    "# Check for infinite values\n",
    "inf_values = X_train.isin([np.inf, -np.inf]).sum()\n",
    "print(\"Infinite values in each column:\\n\", inf_values)\n",
    "\n",
    "# **Feature Selection**\n",
    "\n",
    "### **Filter based Methods** \n",
    "Basic Statistical Filter Methods\n",
    "VarianceThreshod (Remove the Constant Feature and Quasi-Constant Features)\n",
    "Remove Duplicate Features\n",
    "Correlation & Ranking based statistical Filter Methods\n",
    "Pearson’s correlation coefficient\n",
    "Spearman’s rank coefficient\n",
    "Kendall’s rank coefficient\n",
    "Statistical Test based Methods\n",
    "Anova or F-Test\n",
    "Mutual Information\n",
    "Chi Square\n",
    "\n",
    "\n",
    "### ** Basic Statistical Filter Methods **\n",
    "\n",
    "### 1)  VarianceThreshod (Remove the Constant Feature and Quasi-Constant Features)\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "var_thres=VarianceThreshold(threshold=0.01)\n",
    "var_thres.fit(X_train)\n",
    "\n",
    "var_thres.get_support()\n",
    "\n",
    "# Get features which have the variance greater than the set threshold value = 0.1\n",
    "sum(var_thres.get_support())\n",
    "\n",
    "there is no constant,Quasi-constant Features \n",
    "\n",
    "### 2) Duplicate columns\n",
    "\n",
    "X_train_t = X_train.T\n",
    "\n",
    "\n",
    "# Print the duplicate features\n",
    "print(\"Duplicate Features\") \n",
    "print(X_train_t.duplicated(keep = 'first')) # keep : {'first', 'last', False}, default 'first'\n",
    "duplicate_feat = X_train_t.duplicated().sum()\n",
    "print(\"Count of duplicate_feature :\",duplicate_feat)\n",
    "\n",
    "\n",
    "# # Identify rows where values differ\n",
    "difference_indices = X_train.index[X_train['Liabilities_And_StockholderEquity'] != X_train['Assets']].tolist()\n",
    "print(f'Differences found at indices: {difference_indices}')\n",
    "different_rows = X_train.loc[difference_indices]\n",
    "print('Rows with different values:')\n",
    "print(different_rows)\n",
    "\n",
    "# Print the duplicate features Names only\n",
    "duplicate_features = X_train_t[X_train_t.duplicated()].index.values\n",
    "print(\"duplicate_features: \",duplicate_features)\n",
    "\n",
    "# Let drop the duplcate features in original dataframe\n",
    "X_train = X_train.drop(columns=duplicate_features,axis=1)\n",
    "X_train.head()\n",
    "\n",
    "# plt.figure(figsize=(19,20))\n",
    "# sns.scatterplot(data=X_train)\n",
    "\n",
    "### **  Correlation & Ranking based statistical Filter Methods **\n",
    "\n",
    "\n",
    "### 1) Feature Selection with Pearson’s correlation coefficient\n",
    "\n",
    "\n",
    "# cols=X_train.columns\n",
    "# fig, axs = plt.subplots(5, 4, figsize=(20, 15)) \n",
    "# [sns.regplot(y = \"y_train\",x=i, data=X_train,scatter_kws={\"color\": \"blue\"}, \n",
    "#              line_kws={\"color\": \"red\"},ax=axs.flatten()[j]) for j,i in enumerate(cols[0:])]\n",
    "# [axs.flatten()[j].set_title(i) for j,i in enumerate(cols[0:])]\n",
    "# fig.tight_layout()\n",
    "# plt.plot()\n",
    "# cols\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "matrice_correlation = X.corr()\n",
    "\n",
    "# Set the figure size (width, height) in inches to a larger size\n",
    "plt.figure(figsize=(24, 16))  # Increased size for a bigger heatmap\n",
    "\n",
    "# Plot the heatma\n",
    "sns.heatmap(matrice_correlation, annot=True, cmap=plt.cm.CMRmap_r, fmt=\".2f\")\n",
    "\n",
    "# Set the title\n",
    "plt.title('Matrice de corrélation')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Compute the correlation matrix of features\n",
    "corr_matrix = X_train.corr()\n",
    "\n",
    "# Compute correlation of features with the target\n",
    "target_corr = X_train.apply(lambda x: np.corrcoef(x, y_train)[0, 1])\n",
    "\n",
    "# Set the threshold for high correlation\n",
    "threshold = 0.8\n",
    "\n",
    "# Function to find highly correlated groups\n",
    "def find_highly_correlated_groups(corr_matrix, threshold):\n",
    "    correlated_groups = []\n",
    "    visited = set()  # Track features we've already grouped\n",
    "    features = corr_matrix.columns\n",
    "    \n",
    "    for i in range(len(features)):\n",
    "        if features[i] not in visited:\n",
    "            # Find features highly correlated with the current feature\n",
    "            current_group = [features[i]]\n",
    "            for j in range(i + 1, len(features)):\n",
    "                if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                    current_group.append(features[j])\n",
    "                    visited.add(features[j])\n",
    "            \n",
    "            if len(current_group) > 1:  # Only store groups of 2 or more correlated features\n",
    "                correlated_groups.append(current_group)\n",
    "    \n",
    "    return correlated_groups\n",
    "\n",
    "# Get highly correlated groups of features\n",
    "highly_correlated_groups = find_highly_correlated_groups(corr_matrix, threshold)\n",
    "\n",
    "# Function to drop all features except the one most correlated with the target\n",
    "def find_features_to_drop(groups, target_corr):\n",
    "    features_to_drop = []\n",
    "    \n",
    "    for group in groups:\n",
    "        # Find the feature in the group that has the highest correlation with the target\n",
    "        best_feature = max(group, key=lambda x: abs(target_corr[x]))\n",
    "        \n",
    "        # Add all other features from the group to the drop list\n",
    "        for feature in group:\n",
    "            if feature != best_feature:\n",
    "                features_to_drop.append(feature)\n",
    "    \n",
    "    return features_to_drop\n",
    "\n",
    "# Identify features to drop based on correlation with the target\n",
    "features_to_drop = find_features_to_drop(highly_correlated_groups, target_corr)\n",
    "\n",
    "# Print the features to drop\n",
    "print(f\"Features to drop: {features_to_drop}\")\n",
    "\n",
    "# Drop the selected features from X_train and X_test\n",
    "X_train_reduced = X_train.drop(columns=features_to_drop)\n",
    "X_test_reduced = X_test.drop(columns=features_to_drop)\n",
    "\n",
    "# Proceed with training your model on the reduced dataset\n",
    "\n",
    "\n",
    "### 2) Feature Selection with Spearman’s correlation coefficient\n",
    "\n",
    "\n",
    "corr_matrix = X_train.corr(method='spearman')\n",
    "plt.figure(figsize=(24,16))\n",
    "sns.heatmap(corr_matrix,cmap = \"RdYlGn\",annot=True)\n",
    "\n",
    "\n",
    "# Compute correlation of features with the target\n",
    "target_corr = X_train.apply(lambda x: np.corrcoef(x, y_train)[0, 1])\n",
    "\n",
    "# Set the threshold for high correlation\n",
    "threshold = 0.8\n",
    "\n",
    "# Function to find highly correlated groups\n",
    "def find_highly_correlated_groups(corr_matrix, threshold):\n",
    "    correlated_groups = []\n",
    "    visited = set()  # Track features we've already grouped\n",
    "    features = corr_matrix.columns\n",
    "    \n",
    "    for i in range(len(features)):\n",
    "        if features[i] not in visited:\n",
    "            # Find features highly correlated with the current feature\n",
    "            current_group = [features[i]]\n",
    "            for j in range(i + 1, len(features)):\n",
    "                if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                    current_group.append(features[j])\n",
    "                    visited.add(features[j])\n",
    "            \n",
    "            if len(current_group) > 1:  # Only store groups of 2 or more correlated features\n",
    "                correlated_groups.append(current_group)\n",
    "    \n",
    "    return correlated_groups\n",
    "\n",
    "# Get highly correlated groups of features\n",
    "highly_correlated_groups = find_highly_correlated_groups(corr_matrix, threshold)\n",
    "\n",
    "# Function to drop all features except the one most correlated with the target\n",
    "def find_features_to_drop(groups, target_corr):\n",
    "    features_to_drop = []\n",
    "    \n",
    "    for group in groups:\n",
    "        # Find the feature in the group that has the highest correlation with the target\n",
    "        best_feature = max(group, key=lambda x: abs(target_corr[x]))\n",
    "        \n",
    "        # Add all other features from the group to the drop list\n",
    "        for feature in group:\n",
    "            if feature != best_feature:\n",
    "                features_to_drop.append(feature)\n",
    "    \n",
    "    return features_to_drop\n",
    "\n",
    "# Identify features to drop based on correlation with the target\n",
    "features_to_drop = find_features_to_drop(highly_correlated_groups, target_corr)\n",
    "\n",
    "# Print the features to drop\n",
    "print(f\"Features to drop: {features_to_drop}\")\n",
    "\n",
    "# Drop the selected features from X_train and X_test\n",
    "X_train_reduced = X_train.drop(columns=features_to_drop)\n",
    "X_test_reduced = X_test.drop(columns=features_to_drop)\n",
    "\n",
    "# Proceed with training your model on the reduced dataset\n",
    "\n",
    "\n",
    "# Features to drop from Pearson\n",
    "features_to_drop_pearson = ['Assets', 'Current_Assets', 'Current_liabilities', \n",
    "                             'Liabilities_And_StockholderEquity', 'Liabilities', \n",
    "                             'Earning_Before_Interest_And_Taxes', 'NetCash_OperatingActivities']\n",
    "\n",
    "# Features to drop from Spearman\n",
    "features_to_drop_spearman = ['Assets', 'Current_Assets', 'Current_liabilities', \n",
    "                              'Liabilities_And_StockholderEquity', 'Revenues', \n",
    "                              'Liabilities', 'Cash', 'AccountsReceivable', \n",
    "                              'AccountsPayable', 'InterestExpense', \n",
    "                              'LongTerm_Debt', 'Earning_Before_Interest_And_Taxes']\n",
    "\n",
    "# Convert to sets for easier comparison\n",
    "set_pearson = set(features_to_drop_pearson)\n",
    "set_spearman = set(features_to_drop_spearman)\n",
    "\n",
    "# Find unique features\n",
    "unique_to_pearson = set_pearson - set_spearman\n",
    "unique_to_spearman = set_spearman - set_pearson\n",
    "overlapping_features = set_pearson & set_spearman# Combine all features, including unique and overlapping\n",
    "all_features_to_drop = unique_to_pearson.union(unique_to_spearman).union(overlapping_features)\n",
    "\n",
    "# Print results\n",
    "print(f\"Unique features to Pearson: {unique_to_pearson}\")\n",
    "print(f\"Unique features to Spearman: {unique_to_spearman}\")\n",
    "print(f\"Overlapping features: {overlapping_features}\")\n",
    "print(f\"All features to drop: {all_features_to_drop}\")\n",
    "\n",
    "## **Decision**\n",
    "\n",
    "# # Drop features from the training DataFrame (assuming X_train is your training DataFrame)\n",
    "# X_train = X_train.drop(columns=all_features_to_drop, errors='ignore')\n",
    "\n",
    "# # Drop features from the test DataFrame (assuming X_test is your test DataFrame)\n",
    "# X_test = X_test.drop(columns=all_features_to_drop, errors='ignore')\n",
    "\n",
    "# # Check the resulting DataFrames\n",
    "# print(\"Training DataFrame after dropping features:\")\n",
    "# print(X_train.head())\n",
    "\n",
    "# print(\"Test DataFrame after dropping features:\")\n",
    "# print(X_test.head())\n",
    "\n",
    "### ** Statistcal Methods  **\n",
    "\n",
    "### 1) Feature Selection for Classification Problem using Mutual Information(MI)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest,mutual_info_classif\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html#id4\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "# determine the mutual information\n",
    "mutual_info = mutual_info_classif(X_train, y_train)\n",
    "mutual_info\n",
    "\n",
    "mutual_info = pd.Series(mutual_info)\n",
    "mutual_info.index = X_train.columns\n",
    "mutual_info.sort_values(ascending=False)\n",
    "\n",
    "#let's plot the ordered mutual_info values per feature\n",
    "mutual_info.sort_values(ascending=False).plot.bar(figsize=(20, 8))\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "#No we Will select the  top 5 important features\n",
    "sel_five_cols = SelectKBest(mutual_info_classif, k=5)\n",
    "sel_five_cols.fit(X_train, y_train)\n",
    "X_train.columns[sel_five_cols.get_support()]\n",
    "\n",
    "# Index(['Stockholder_Equity', 'Retained_Earnings', 'Working_capital',\n",
    "#        'Liabilities', 'LongTerm_Debt'],\n",
    "#       dtype='object')\n",
    "\n",
    "### **Wrapper Methods** \n",
    "\n",
    "\n",
    "### ** Forword selection  **\n",
    "\n",
    "\n",
    "\n",
    "## **Balancing the data**\n",
    "\n",
    "## undersampling\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Use X_train_successful dataset with all features (except target variable)\n",
    "X_train_successful = X_train[y_train == 0]\n",
    "y_train_successful = y_train[y_train == 0]\n",
    "\n",
    "# Assuming X_train_successful has only the features (exclude the target if needed)\n",
    "X = X_train_successful  # All features\n",
    "\n",
    "# Elbow Method and Silhouette Score to find the best k\n",
    "wcss = []  # Store WCSS values for Elbow method\n",
    "silhouette_scores = []  # Store silhouette scores\n",
    "K_range = range(2, 11)  # Testing k from 2 to 10\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(X)\n",
    "    \n",
    "    # Append WCSS (within-cluster sum of squares) for the Elbow method\n",
    "    wcss.append(kmeans.inertia_)\n",
    "    \n",
    "    # Append silhouette score (quality of clustering)\n",
    "    silhouette_avg = silhouette_score(X, kmeans.labels_)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# Plot Elbow Method (WCSS)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Elbow Method plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(K_range, wcss, marker='o')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('WCSS (Within-cluster sum of squares)')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot Silhouette Scores\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(K_range, silhouette_scores, marker='o', color='orange')\n",
    "plt.title('Silhouette Scores')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Suggest the best k using the Elbow Method (find the elbow point)\n",
    "# Calculate the differences between consecutive WCSS values to locate the elbow\n",
    "wcss_differences = np.diff(wcss)\n",
    "\n",
    "# # Find the point where the decrease slows down the most (the \"elbow\")\n",
    "# elbow_k = K_range[np.argmin(np.abs(np.diff(wcss_differences))) + 1]\n",
    "# print(f\"The best number of clusters based on the Elbow Method is: {elbow_k}\")\n",
    "elbow_k=4\n",
    "# Now, create and fit the K-Means model using the best k (from the Elbow Method)\n",
    "kmeans = KMeans(n_clusters=elbow_k, random_state=0)\n",
    "X['Cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Example for 2D Visualization (using PCA to reduce to 2 components)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X.drop('Cluster', axis=1))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=X['Cluster'], cmap='viridis')\n",
    "plt.title(f'Clustering with k={elbow_k} (2D PCA)')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Display the first few rows of the clustered data\n",
    "X.head()\n",
    "\n",
    "\n",
    "\n",
    "# Suggest the best k using the Elbow Method\n",
    "elbow_k = 4  # For example, you've determined that k = 5 is optimal\n",
    "print(f\"The best number of clusters based on the Elbow Method is: {elbow_k}\")\n",
    "\n",
    "# Now, create and fit the K-Means model using the best k (from the Elbow Method)\n",
    "kmeans = KMeans(n_clusters=elbow_k, random_state=0)\n",
    "X['Cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Create DataFrames for each cluster\n",
    "clustered_data = {}\n",
    "for cluster in range(elbow_k):  # From 0 to 4 (for k=5)\n",
    "    clustered_data[f'Cluster_{cluster + 1}'] = X[X['Cluster'] == cluster]\n",
    "\n",
    "# Determine the number of samples to take from each cluster\n",
    "total_samples = 200\n",
    "samples_per_cluster = total_samples // elbow_k  # Equal samples from each cluster\n",
    "\n",
    "# Undersample each cluster\n",
    "undersampled_dfs = []\n",
    "for key, df in clustered_data.items():\n",
    "    if df.shape[0] >= samples_per_cluster:  # Ensure there are enough samples\n",
    "        undersampled_df = df.sample(n=samples_per_cluster, random_state=0)\n",
    "        undersampled_dfs.append(undersampled_df)\n",
    "    else:\n",
    "        print(f\"Cluster {key} has only {df.shape[0]} samples, not enough to undersample to {samples_per_cluster}.\")\n",
    "\n",
    "# Combine the undersampled DataFrames\n",
    "X_train = pd.concat(undersampled_dfs, ignore_index=True)\n",
    "\n",
    "# Display the final undersampled DataFrame\n",
    "print(\"\\nFinal Undersampled DataFrame:\")\n",
    "print(final_undersampled_df.head())\n",
    "print(f\"Total rows in final DataFrame: {final_undersampled_df.shape[0]}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Oversampling \n",
    "\n",
    "### Apply SMOTE\n",
    "\n",
    "\n",
    "# #!pip install imbalanced-learn\n",
    "\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from sklearn.datasets import make_classification\n",
    "\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "### Apply ADASYN\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Apply ADASYN to the training data\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_train, y_train= adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "c=y_train.value_counts()\n",
    "plt.pie(c, labels=['stay', 'is_bankrupt'], autopct='%1.1f%%', startangle=90, colors=['skyblue', 'lightcoral'])\n",
    "plt.title('Distribution des employés (is_bankrupt vs healthy)')\n",
    "plt.show()\n",
    "c\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shatest.shape)\n",
    "pe)\n",
    "print(y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "\n",
    "**1- Random Forest**\n",
    "\n",
    "A powerful ensemble learning method that builds multiple decision trees and combines their predictions to improve accuracy and robustness.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# ================== Random Forest without Feature Selection ==================\n",
    "# Train a Random Forest classifier without feature selection\n",
    "rf_w = RandomForestClassifier(random_state=100, n_estimators=50)\n",
    "rf_w.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate accuracy\n",
    "y_pred_rf_w = rf_w.predict(X_test)\n",
    "accuracy_rf_w = accuracy_score(y_test, y_pred_rf_w)\n",
    "print(f\"Random Forest Accuracy (without feature selection): {accuracy_rf_w:.4f}\")\n",
    "\n",
    "# ================== Feature Importance (Without Feature Selection) ================\n",
    "# Get feature importance from the trained Random Forest model\n",
    "importances = rf_w.feature_importances_\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "final_df = pd.DataFrame({\"Features\": X_train.columns, \"Importances\": importances})\n",
    "final_df.set_index('Importances')\n",
    "\n",
    "# Sort features by importance in ascending order for better visualization\n",
    "final_df = final_df.sort_values('Importances')\n",
    "\n",
    "# Plot the feature importances as a bar chart\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.xticks(rotation=45)\n",
    "sns.barplot(x=\"Features\", y=\"Importances\", data=final_df)\n",
    "plt.title(\"Feature Importance (Random Forest without feature selection)\")\n",
    "plt.show()\n",
    "\n",
    "# ================== Random Forest with RFE (Feature Selection) ==================\n",
    "# Define a new Random Forest model for RFE (Recursive Feature Elimination)\n",
    "model_tree = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Apply RFE to select the top 7 most important features\n",
    "sel_rfe_tree = RFE(estimator=model_tree, n_features_to_select=8, step=1)\n",
    "X_train_rfe_tree = sel_rfe_tree.fit_transform(X_train, y_train)\n",
    "X_test_rfe_tree = sel_rfe_tree.transform(X_test)\n",
    "\n",
    "# Print selected features and their rankings\n",
    "print(f\"Selected Features Support: {sel_rfe_tree.get_support()}\")\n",
    "print(f\"Feature Rankings: {sel_rfe_tree.ranking_}\")\n",
    "\n",
    "# Train a Random Forest model using RFE-selected features\n",
    "rf_rfe = RandomForestClassifier(random_state=42)\n",
    "rf_rfe.fit(X_train_rfe_tree, y_train)\n",
    "\n",
    "# Make predictions and evaluate accuracy\n",
    "y_pred_rf_rfe = rf_rfe.predict(X_test_rfe_tree)\n",
    "accuracy_rf_rfe = accuracy_score(y_test, y_pred_rf_rfe)\n",
    "print(f\"Random Forest Accuracy (with RFE): {accuracy_rf_rfe:.4f}\")\n",
    "\n",
    "# find the number of selected features with the help of the following script:\n",
    "selected_cols = [column for column in X_train.columns if column in X_train.columns[sel_rfe_tree.get_support()]]\n",
    "selected_cols\n",
    "\n",
    "# ================== Hyperparameter Tuning on Selected Features ==================\n",
    "# Perform Grid Search to tune hyperparameters on RFE-selected features\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "grid_search_rf_rfe = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid_rf,\n",
    "    scoring='roc_auc',\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the Grid Search model\n",
    "grid_search_rf_rfe.fit(X_train_rfe_tree, y_train)\n",
    "\n",
    "# Get the best parameters and the tuned model\n",
    "best_params_rf_rfe = grid_search_rf_rfe.best_params_\n",
    "tuned_rf_model_rfe = grid_search_rf_rfe.best_estimator_\n",
    "\n",
    "# Evaluate the tuned model\n",
    "y_pred_rf_rfe_tuned = tuned_rf_model_rfe.predict(X_test_rfe_tree)\n",
    "accuracy_rf_rfe_tuned = accuracy_score(y_test, y_pred_rf_rfe_tuned)\n",
    "print(f\"Tuned Random Forest (with RFE) Accuracy: {accuracy_rf_rfe_tuned:.4f}\")\n",
    "\n",
    "**2- Decision Tree**\n",
    "\n",
    "Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Baseline Decision Tree model\n",
    "baseline_dt_model = DecisionTreeClassifier(random_state=42)\n",
    "baseline_dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Baseline predictions\n",
    "y_pred_baseline_dt = baseline_dt_model.predict(X_test)\n",
    "y_pred_baseline_dt_proba = baseline_dt_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Baseline model evaluation\n",
    "accuracy_baseline_dt = accuracy_score(y_test, y_pred_baseline_dt)\n",
    "auc_baseline_dt = roc_auc_score(y_test, y_pred_baseline_dt_proba)\n",
    "print(f\"Baseline Decision Tree Accuracy: {accuracy_baseline_dt:.4f}\")\n",
    "print(f\"Baseline Decision Tree AUC: {auc_baseline_dt:.4f}\")\n",
    "\n",
    "# 2. Hyperparameter tuning with Grid Search for Decision Tree\n",
    "param_grid_dt = {\n",
    "    'max_depth': [3, 5, 7, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# GridSearchCV setup for Decision Tree\n",
    "grid_search_dt = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(random_state=42),\n",
    "    param_grid=param_grid_dt,\n",
    "    scoring='roc_auc',\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit Grid Search for Decision Tree\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "best_params_dt = grid_search_dt.best_params_\n",
    "print(f\"Best Decision Tree parameters found: {best_params_dt}\")\n",
    "\n",
    "# 3. Evaluate tuned model with cross-validation\n",
    "tuned_dt_model = grid_search_dt.best_estimator_\n",
    "\n",
    "# Cross-validation with the tuned Decision Tree model (5 folds)\n",
    "cv_results_dt = cross_val_score(tuned_dt_model, X_train, y_train, cv=StratifiedKFold(n_splits=5), scoring='roc_auc')\n",
    "print(f\"Cross-validation AUC scores (Decision Tree): {cv_results_dt}\")\n",
    "print(f\"Mean Cross-validation AUC (Decision Tree): {cv_results_dt.mean():.4f}\")\n",
    "\n",
    "# 4. Final Decision Tree model and evaluation\n",
    "tuned_dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt = tuned_dt_model.predict(X_test)\n",
    "y_pred_dt_proba = tuned_dt_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "precision_dt = precision_score(y_test, y_pred_dt)\n",
    "recall_dt = recall_score(y_test, y_pred_dt)\n",
    "f1_dt = f1_score(y_test, y_pred_dt)\n",
    "auc_dt = roc_auc_score(y_test, y_pred_dt_proba)\n",
    "\n",
    "print(f\"Tuned Decision Tree Accuracy: {accuracy_dt:.4f}\")\n",
    "print(f\"Tuned Decision Tree Precision: {precision_dt:.4f}\")\n",
    "print(f\"Tuned Decision Tree Recall: {recall_dt:.4f}\")\n",
    "print(f\"Tuned Decision Tree F1 Score: {f1_dt:.4f}\")\n",
    "print(f\"Tuned Decision Tree AUC: {auc_dt:.4f}\")\n",
    "\n",
    "# Plot ROC curve for Decision Tree\n",
    "fpr_dt, tpr_dt, thresholds_dt = roc_curve(y_test, y_pred_dt_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_dt, tpr_dt, color='blue', label=f'Decision Tree ROC (AUC = {auc_dt:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.title('Decision Tree ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "**1- SVM**\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Baseline SVM model\n",
    "baseline_svm_model = SVC(random_state=42, probability=True)\n",
    "baseline_svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Baseline predictions\n",
    "y_pred_baseline_svm = baseline_svm_model.predict(X_test)\n",
    "y_pred_baseline_svm_proba = baseline_svm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Baseline model evaluation\n",
    "accuracy_baseline_svm = accuracy_score(y_test, y_pred_baseline_svm)\n",
    "auc_baseline_svm = roc_auc_score(y_test, y_pred_baseline_svm_proba)\n",
    "print(f\"Baseline SVM Accuracy: {accuracy_baseline_svm:.4f}\")\n",
    "print(f\"Baseline SVM AUC: {auc_baseline_svm:.4f}\")\n",
    "\n",
    "# 2. Hyperparameter tuning with Grid Search for SVM\n",
    "# param_grid_svm = {\n",
    "#     'C': [0.1, 1, 10, 100],\n",
    "#     'kernel': ['linear', 'rbf', 'poly'],\n",
    "#     'gamma': ['scale', 'auto'],\n",
    "#     'degree': [2, 3, 4]  # Only applicable for 'poly' kernel\n",
    "# }\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'poly'],\n",
    "    'degree': [2, 3]  \n",
    "}\n",
    "\n",
    "# GridSearchCV setup for SVM\n",
    "grid_search_svm = GridSearchCV(\n",
    "    estimator=SVC(random_state=42, probability=True),\n",
    "    param_grid=param_grid_svm,\n",
    "    scoring='roc_auc',\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit Grid Search for SVM\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "best_params_svm = grid_search_svm.best_params_\n",
    "print(f\"Best SVM parameters found: {best_params_svm}\")\n",
    "\n",
    "# 3. Evaluate tuned model with cross-validation\n",
    "tuned_svm_model = grid_search_svm.best_estimator_\n",
    "\n",
    "# Cross-validation with the tuned SVM model (5 folds)\n",
    "cv_results_svm = cross_val_score(tuned_svm_model, X_train, y_train, cv=StratifiedKFold(n_splits=5), scoring='roc_auc')\n",
    "print(f\"Cross-validation AUC scores (SVM): {cv_results_svm}\")\n",
    "print(f\"Mean Cross-validation AUC (SVM): {cv_results_svm.mean():.4f}\")\n",
    "\n",
    "# 4. Final SVM model and evaluation\n",
    "tuned_svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = tuned_svm_model.predict(X_test)\n",
    "y_pred_svm_proba = tuned_svm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "auc_svm = roc_auc_score(y_test, y_pred_svm_proba)\n",
    "\n",
    "print(f\"Tuned SVM Accuracy: {accuracy_svm:.4f}\")\n",
    "print(f\"Tuned SVM Precision: {precision_svm:.4f}\")\n",
    "print(f\"Tuned SVM Recall: {recall_svm:.4f}\")\n",
    "print(f\"Tuned SVM F1 Score: {f1_svm:.4f}\")\n",
    "print(f\"Tuned SVM AUC: {auc_svm:.4f}\")\n",
    "\n",
    "# Plot ROC curve for SVM\n",
    "fpr_svm, tpr_svm, thresholds_svm = roc_curve(y_test, y_pred_svm_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_svm, tpr_svm, color='blue', label=f'SVM ROC (AUC = {auc_svm:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.title('SVM ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "**4-fully connected neural network**\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "model = Sequential([\n",
    "    Dense(units=20, input_dim = X_train.shape[1], activation='relu'),\n",
    "    Dense(units=24,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=20,activation='relu'),\n",
    "    Dense(units=24,activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=30, epochs=30)\n",
    "\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy: {:.2f}%\\nTest Loss: {}'.format(score[1]*100,score[0]))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "cm = confusion_matrix(y_test, y_pred.round())\n",
    "sns.heatmap(cm, annot=True, fmt='.0f')\n",
    "plt.show()\n",
    "\n",
    "**5- XgBoost**\n",
    "\n",
    "An implementation of gradient boosting specifically designed to be efficient and effective. It often performs better than other boosting methods.\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Load your data (X_train, X_test, y_train, y_test)\n",
    "\n",
    "# 1. Start with a baseline model\n",
    "baseline_model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='auc', use_label_encoder=False)\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Baseline predictions\n",
    "y_pred_baseline = baseline_model.predict(X_test)\n",
    "y_pred_baseline_proba = baseline_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Baseline model evaluation\n",
    "accuracy_baseline = accuracy_score(y_test, y_pred_baseline)\n",
    "auc_baseline = roc_auc_score(y_test, y_pred_baseline_proba)\n",
    "print(f\"Baseline Accuracy: {accuracy_baseline:.4f}\")\n",
    "print(f\"Baseline AUC: {auc_baseline:.4f}\")\n",
    "\n",
    "# 2. Hyperparameter tuning with Grid Search\n",
    "param_grid = {\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'n_estimators': [100, 200]\n",
    "}\n",
    "\n",
    "# GridSearchCV setup\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb.XGBClassifier(objective='binary:logistic', eval_metric='auc', use_label_encoder=False),\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit Grid Search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "# 3. Evaluate tuned model with cross-validation\n",
    "tuned_model = grid_search.best_estimator_\n",
    "\n",
    "# Cross-validation with the tuned model (5 folds)\n",
    "cv_results = cross_val_score(tuned_model, X_train, y_train, cv=StratifiedKFold(n_splits=5), scoring='roc_auc')\n",
    "print(f\"Cross-validation AUC scores: {cv_results}\")\n",
    "print(f\"Mean Cross-validation AUC: {cv_results.mean():.4f}\")\n",
    "\n",
    "# 4. Train final model on the full training data using best parameters\n",
    "tuned_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = tuned_model.predict(X_test)\n",
    "y_pred_proba = tuned_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Tuned Model Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Tuned Model Precision: {precision:.4f}\")\n",
    "print(f\"Tuned Model Recall: {recall:.4f}\")\n",
    "print(f\"Tuned Model F1 Score: {f1:.4f}\")\n",
    "print(f\"Tuned Model AUC: {auc:.4f}\")\n",
    "\n",
    "# Plot ROC curve for tuned model\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "**3- BaggingClassifier**\n",
    "\n",
    "A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction.\n",
    "\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Baseline Bagging Classifier model\n",
    "baseline_bagging_model = BaggingClassifier(random_state=42)\n",
    "baseline_bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# Baseline predictions\n",
    "y_pred_baseline_bagging = baseline_bagging_model.predict(X_test)\n",
    "y_pred_baseline_bagging_proba = baseline_bagging_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Baseline model evaluation\n",
    "accuracy_baseline_bagging = accuracy_score(y_test, y_pred_baseline_bagging)\n",
    "auc_baseline_bagging = roc_auc_score(y_test, y_pred_baseline_bagging_proba)\n",
    "print(f\"Baseline Bagging Classifier Accuracy: {accuracy_baseline_bagging:.4f}\")\n",
    "print(f\"Baseline Bagging Classifier AUC: {auc_baseline_bagging:.4f}\")\n",
    "\n",
    "# 2. Hyperparameter tuning with Grid Search for Bagging Classifier\n",
    "param_grid_bagging = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.5, 0.7, 1.0],\n",
    "    'bootstrap': [True, False],\n",
    "    'bootstrap_features': [True, False]\n",
    "}\n",
    "\n",
    "# GridSearchCV setup for Bagging Classifier\n",
    "grid_search_bagging = GridSearchCV(\n",
    "    estimator=BaggingClassifier(random_state=42),\n",
    "    param_grid=param_grid_bagging,\n",
    "    scoring='roc_auc',\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit Grid Search for Bagging Classifier\n",
    "grid_search_bagging.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "best_params_bagging = grid_search_bagging.best_params_\n",
    "print(f\"Best Bagging Classifier parameters found: {best_params_bagging}\")\n",
    "\n",
    "# 3. Evaluate tuned model with cross-validation\n",
    "tuned_bagging_model = grid_search_bagging.best_estimator_\n",
    "\n",
    "# Cross-validation with the tuned Bagging Classifier model (5 folds)\n",
    "cv_results_bagging = cross_val_score(tuned_bagging_model, X_train, y_train, cv=StratifiedKFold(n_splits=5), scoring='roc_auc')\n",
    "print(f\"Cross-validation AUC scores (Bagging Classifier): {cv_results_bagging}\")\n",
    "print(f\"Mean Cross-validation AUC (Bagging Classifier): {cv_results_bagging.mean():.4f}\")\n",
    "\n",
    "# 4. Final Bagging Classifier model and evaluation\n",
    "tuned_bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_bagging = tuned_bagging_model.predict(X_test)\n",
    "y_pred_bagging_proba = tuned_bagging_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "precision_bagging = precision_score(y_test, y_pred_bagging)\n",
    "recall_bagging = recall_score(y_test, y_pred_bagging)\n",
    "f1_bagging = f1_score(y_test, y_pred_bagging)\n",
    "auc_bagging = roc_auc_score(y_test, y_pred_bagging_proba)\n",
    "\n",
    "print(f\"Tuned Bagging Classifier Accuracy: {accuracy_bagging:.4f}\")\n",
    "print(f\"Tuned Bagging Classifier Precision: {precision_bagging:.4f}\")\n",
    "print(f\"Tuned Bagging Classifier Recall: {recall_bagging:.4f}\")\n",
    "print(f\"Tuned Bagging Classifier F1 Score: {f1_bagging:.4f}\")\n",
    "print(f\"Tuned Bagging Classifier AUC: {auc_bagging:.4f}\")\n",
    "\n",
    "# Plot ROC curve for Bagging Classifier\n",
    "fpr_bagging, tpr_bagging, thresholds_bagging = roc_curve(y_test, y_pred_bagging_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_bagging, tpr_bagging, color='blue', label=f'Bagging Classifier ROC (AUC = {auc_bagging:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.title('Bagging Classifier ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "**4- Extra Trees Classifier (Extremely Randomized Trees)**\n",
    "\n",
    "Similar to a Random Forest, but with a key difference in how trees are constructed. In Extra Trees, both the selection of the split points and the features to split on are randomized, which can lead to better performance in some cases.\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# 1. Baseline ExtraTrees Classifier model\n",
    "baseline_extratree_model = ExtraTreesClassifier(random_state=42)\n",
    "baseline_extratree_model.fit(X_train, y_train)\n",
    "\n",
    "# Baseline predictions\n",
    "y_pred_baseline_extratree = baseline_extratree_model.predict(X_test)\n",
    "y_pred_baseline_extratree_proba = baseline_extratree_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Baseline model evaluation\n",
    "accuracy_baseline_extratree = accuracy_score(y_test, y_pred_baseline_extratree)\n",
    "auc_baseline_extratree = roc_auc_score(y_test, y_pred_baseline_extratree_proba)\n",
    "print(f\"Baseline ExtraTrees Classifier Accuracy: {accuracy_baseline_extratree:.4f}\")\n",
    "print(f\"Baseline ExtraTrees Classifier AUC: {auc_baseline_extratree:.4f}\")\n",
    "\n",
    "# 2. Hyperparameter tuning with Grid Search for ExtraTrees Classifier\n",
    "param_grid_extratree = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# GridSearchCV setup for ExtraTrees Classifier\n",
    "grid_search_extratree = GridSearchCV(\n",
    "    estimator=ExtraTreesClassifier(random_state=42),\n",
    "    param_grid=param_grid_extratree,\n",
    "    scoring='roc_auc',\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit Grid Search for ExtraTrees Classifier\n",
    "grid_search_extratree.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "best_params_extratree = grid_search_extratree.best_params_\n",
    "print(f\"Best ExtraTrees Classifier parameters found: {best_params_extratree}\")\n",
    "\n",
    "# 3. Evaluate tuned model with cross-validation\n",
    "tuned_extratree_model = grid_search_extratree.best_estimator_\n",
    "\n",
    "# Cross-validation with the tuned ExtraTrees Classifier model (5 folds)\n",
    "cv_results_extratree = cross_val_score(tuned_extratree_model, X_train, y_train, cv=StratifiedKFold(n_splits=5), scoring='roc_auc')\n",
    "print(f\"Cross-validation AUC scores (ExtraTrees Classifier): {cv_results_extratree}\")\n",
    "print(f\"Mean Cross-validation AUC (ExtraTrees Classifier): {cv_results_extratree.mean():.4f}\")\n",
    "\n",
    "# 4. Final ExtraTrees Classifier model and evaluation\n",
    "tuned_extratree_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_extratree = tuned_extratree_model.predict(X_test)\n",
    "y_pred_extratree_proba = tuned_extratree_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy_extratree = accuracy_score(y_test, y_pred_extratree)\n",
    "precision_extratree = precision_score(y_test, y_pred_extratree)\n",
    "recall_extratree = recall_score(y_test, y_pred_extratree)\n",
    "f1_extratree = f1_score(y_test, y_pred_extratree)\n",
    "auc_extratree = roc_auc_score(y_test, y_pred_extratree_proba)\n",
    "\n",
    "print(f\"Tuned ExtraTrees Classifier Accuracy: {accuracy_extratree:.4f}\")\n",
    "print(f\"Tuned ExtraTrees Classifier Precision: {precision_extratree:.4f}\")\n",
    "print(f\"Tuned ExtraTrees Classifier Recall: {recall_extratree:.4f}\")\n",
    "print(f\"Tuned ExtraTrees Classifier F1 Score: {f1_extratree:.4f}\")\n",
    "print(f\"Tuned ExtraTrees Classifier AUC: {auc_extratree:.4f}\")\n",
    "\n",
    "# Plot ROC curve for ExtraTrees Classifier\n",
    "fpr_extratree, tpr_extratree, thresholds_extratree = roc_curve(y_test, y_pred_extratree_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_extratree, tpr_extratree, color='blue', label=f'ExtraTrees Classifier ROC (AUC = {auc_extratree:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.title('ExtraTrees Classifier ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "**6- LightGBM Classifier**\n",
    "\n",
    "A gradient boosting framework that uses decision trees and is designed to be distributed and efficient, especially on large datasets. It's known for its speed and performance\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Baseline LightGBM model\n",
    "baseline_lgb_model = lgb.LGBMClassifier(random_state=42)\n",
    "baseline_lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Baseline predictions\n",
    "y_pred_baseline_lgb = baseline_lgb_model.predict(X_test)\n",
    "y_pred_baseline_lgb_proba = baseline_lgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Baseline model evaluation\n",
    "accuracy_baseline_lgb = accuracy_score(y_test, y_pred_baseline_lgb)\n",
    "auc_baseline_lgb = roc_auc_score(y_test, y_pred_baseline_lgb_proba)\n",
    "print(f\"Baseline LightGBM Accuracy: {accuracy_baseline_lgb:.4f}\")\n",
    "print(f\"Baseline LightGBM AUC: {auc_baseline_lgb:.4f}\")\n",
    "\n",
    "\n",
    "# 2. Hyperparameter tuning with Grid Search for LightGBM\n",
    "param_grid_lgb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, -1],  # -1 means no limit\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.3],\n",
    "    'num_leaves': [31, 63, 127],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.01, 0.1],\n",
    "    'reg_lambda': [0, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# GridSearchCV setup for LightGBM\n",
    "grid_search_lgb = GridSearchCV(\n",
    "    estimator=lgb.LGBMClassifier(random_state=42),\n",
    "    param_grid=param_grid_lgb,\n",
    "    scoring='roc_auc',\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit Grid Search for LightGBM\n",
    "grid_search_lgb.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "best_params_lgb = grid_search_lgb.best_params_\n",
    "print(f\"Best LightGBM parameters found: {best_params_lgb}\")\n",
    "\n",
    "\n",
    "# 3. Evaluate tuned model with cross-validation\n",
    "tuned_lgb_model = grid_search_lgb.best_estimator_\n",
    "\n",
    "# Cross-validation with the tuned LightGBM model (5 folds)\n",
    "cv_results_lgb = cross_val_score(tuned_lgb_model, X_train, y_train, cv=StratifiedKFold(n_splits=5), scoring='roc_auc')\n",
    "print(f\"Cross-validation AUC scores (LightGBM): {cv_results_lgb}\")\n",
    "print(f\"Mean Cross-validation AUC (LightGBM): {cv_results_lgb.mean():.4f}\")\n",
    "\n",
    "\n",
    "# 4. Final LightGBM model and evaluation\n",
    "tuned_lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lgb = tuned_lgb_model.predict(X_test)\n",
    "y_pred_lgb_proba = tuned_lgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy_lgb = accuracy_score(y_test, y_pred_lgb)\n",
    "precision_lgb = precision_score(y_test, y_pred_lgb)\n",
    "recall_lgb = recall_score(y_test, y_pred_lgb)\n",
    "f1_lgb = f1_score(y_test, y_pred_lgb)\n",
    "auc_lgb = roc_auc_score(y_test, y_pred_lgb_proba)\n",
    "\n",
    "print(f\"Tuned LightGBM Accuracy: {accuracy_lgb:.4f}\")\n",
    "print(f\"Tuned LightGBM Precision: {precision_lgb:.4f}\")\n",
    "print(f\"Tuned LightGBM Recall: {recall_lgb:.4f}\")\n",
    "print(f\"Tuned LightGBM F1 Score: {f1_lgb:.4f}\")\n",
    "print(f\"Tuned LightGBM AUC: {auc_lgb:.4f}\")\n",
    "\n",
    "# Plot ROC curve for LightGBM\n",
    "fpr_lgb, tpr_lgb, thresholds_lgb = roc_curve(y_test, y_pred_lgb_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_lgb, tpr_lgb, color='blue', label=f'LightGBM ROC (AUC = {auc_lgb:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.title('LightGBM ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Collect all evaluation metrics\n",
    "results = [\n",
    "    {'Model': 'Decision Tree', 'Accuracy': accuracy_dt, 'Precision': precision_dt, 'Recall': recall_dt, 'F1 Score': f1_dt, 'AUC': auc_dt},\n",
    "    {'Model': 'Bagging Classifier', 'Accuracy': accuracy_bagging, 'Precision': precision_bagging, 'Recall': recall_bagging, 'F1 Score': f1_bagging, 'AUC': auc_bagging},\n",
    "    {'Model': 'Random Forest', 'Accuracy': accuracy_rf, 'Precision': precision_rf, 'Recall': recall_rf, 'F1 Score': f1_rf, 'AUC': auc_rf},\n",
    "    {'Model': 'Extra Trees', 'Accuracy': accuracy_extratree, 'Precision': precision_extratree, 'Recall': recall_extratree, 'F1 Score': f1_extratree, 'AUC': auc_extratree},\n",
    "    # {'Model': 'LightGBM', 'Accuracy': accuracy_lgb, 'Precision': precision_lgb, 'Recall': recall_lgb, 'F1 Score': f1_lgb, 'AUC': auc_lgb},\n",
    "    {'Model': 'XGboost', 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1, 'AUC': auc},\n",
    "\n",
    "]\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the results\n",
    "print(results_df)\n",
    "\n",
    "# Plotting the results\n",
    "fig, ax = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot Accuracy\n",
    "results_df.set_index('Model')['Accuracy'].plot(kind='bar', ax=ax[0, 0], color='skyblue', legend=False)\n",
    "ax[0, 0].set_title('Model Accuracy')\n",
    "ax[0, 0].set_ylabel('Accuracy')\n",
    "\n",
    "# Plot Precision\n",
    "results_df.set_index('Model')['Precision'].plot(kind='bar', ax=ax[0, 1], color='salmon', legend=False)\n",
    "ax[0, 1].set_title('Model Precision')\n",
    "ax[0, 1].set_ylabel('Precision')\n",
    "\n",
    "# Plot Recall\n",
    "results_df.set_index('Model')['Recall'].plot(kind='bar', ax=ax[1, 0], color='lightgreen', legend=False)\n",
    "ax[1, 0].set_title('Model Recall')\n",
    "ax[1, 0].set_ylabel('Recall')\n",
    "\n",
    "# Plot F1 Score\n",
    "results_df.set_index('Model')['F1 Score'].plot(kind='bar', ax=ax[1, 1], color='orange', legend=False)\n",
    "ax[1, 1].set_title('Model F1 Score')\n",
    "ax[1, 1].set_ylabel('F1 Score')\n",
    "\n",
    "# Plot AUC\n",
    "fig, ax2 = plt.subplots(figsize=(12, 6))\n",
    "results_df.set_index('Model')['AUC'].plot(kind='bar', color='purple', legend=False, ax=ax2)\n",
    "ax2.set_title('Model AUC')\n",
    "ax2.set_ylabel('AUC')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm forcast bunkrupsy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Convert 'filed' to datetime and sort by date\n",
    "data['filed'] = pd.to_datetime(data['filed'])\n",
    "data = data.sort_values(by='filed')\n",
    "\n",
    "# Create lag features (e.g., past values of financial metrics)\n",
    "data['Assets_lag1'] = data['Assets'].shift(1)\n",
    "data['NetIncome_lag1'] = data['NetIncome'].shift(1)\n",
    "\n",
    "# Drop missing values (caused by shifting/lagging)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Features (lagged financial data) and target (is_bankrupt)\n",
    "features = ['Assets_lag1', 'NetIncome_lag1']\n",
    "X = data[features]\n",
    "y = data['is_bankrupt']\n",
    "\n",
    "# Split data into training and testing sets before scaling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Scale the features after the split to avoid data leakage\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape input for LSTM [samples, timesteps, features]\n",
    "X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# Define a function to build the LSTM model (required for KerasClassifier)\n",
    "def create_model(units=50, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, return_sequences=False, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2])))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binary output (0 or 1)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap the model using KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'units': [50, 100],  # Number of LSTM units\n",
    "    'dropout_rate': [0.2, 0.4],  # Dropout rates\n",
    "    'batch_size': [32, 64],  # Batch sizes\n",
    "    'epochs': [10, 20]  # Number of epochs\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=1)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "\n",
    "# Use the best model to predict on the test set\n",
    "best_model = grid_result.best_estimator_\n",
    "y_pred_prob = best_model.predict(X_test_scaled)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "# Evaluate the best model\n",
    "print(classification_report(y_test, y_pred))\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "\n",
    "\n",
    "# arima( credit score )\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your dataset\n",
    "# data = pd.read_csv('your_data.csv')  # Replace with your actual data path\n",
    "\n",
    "# Convert 'filed' to datetime and sort by date\n",
    "data['filed'] = pd.to_datetime(data['filed'])\n",
    "data = data.sort_values(by='filed')\n",
    "\n",
    "# Extract 'filed' and 'CreditScore'\n",
    "credit_score_data = data.set_index('filed')['CreditScore'].dropna()\n",
    "\n",
    "# Train-test split\n",
    "train_size = int(len(credit_score_data) * 0.8)\n",
    "train_data, test_data = credit_score_data[:train_size], credit_score_data[train_size:]\n",
    "\n",
    "# Fit ARIMA model on training data\n",
    "model = ARIMA(train_data, order=(5, 1, 0))\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Forecast on test data\n",
    "forecast = model_fit.forecast(steps=len(test_data))\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(test_data, forecast)\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "\n",
    "# Plot actual vs. forecasted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_data.index, train_data, label='Train')\n",
    "plt.plot(test_data.index, test_data, label='Test')\n",
    "plt.plot(test_data.index, forecast, label='Forecast')\n",
    "plt.title('CreditScore Forecast using ARIMA')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('CreditScore')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transformers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[142], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define Transformer model class\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim, num_heads, num_encoder_layers, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=model_dim, nhead=num_heads, dropout=dropout\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            self.encoder_layer, num_layers=num_encoder_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(model_dim, 1)\n",
    "\n",
    "    def forward(self, src):\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.fc(output[-1])\n",
    "        return output\n",
    "\n",
    "# Convert 'filed' to datetime and sort by date\n",
    "data['filed'] = pd.to_datetime(data['filed'])\n",
    "data = data.sort_values(by='filed')\n",
    "\n",
    "# Extract 'filed' and 'CreditScore'\n",
    "credit_score_data = data.set_index('filed')['CreditScore'].dropna()\n",
    "\n",
    "# Train-test split\n",
    "train_size = int(len(credit_score_data) * 0.8)\n",
    "train_data, test_data = credit_score_data[:train_size], credit_score_data[train_size:]\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "train_data_scaled = scaler.fit_transform(train_data.values.reshape(-1, 1))\n",
    "test_data_scaled = scaler.transform(test_data.values.reshape(-1, 1))\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_data_tensor = torch.tensor(train_data_scaled, dtype=torch.float32).view(-1, 1)\n",
    "test_data_tensor = torch.tensor(test_data_scaled, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Define Transformer model\n",
    "model = TransformerModel(input_dim=1, model_dim=64, num_heads=4, num_encoder_layers=3, dropout=0.2)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(train_data_tensor.unsqueeze(1))  # Add dimension for sequence length\n",
    "    loss = criterion(output, train_data_tensor[-1])  # Compare only last value\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Forecast on test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predicted = model(test_data_tensor.unsqueeze(1))\n",
    "\n",
    "# Inverse scale the predictions\n",
    "predicted_inverse = scaler.inverse_transform(predicted.detach().numpy())\n",
    "\n",
    "# Plot actual vs predicted CreditScore\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_data.index, test_data.values, label='Actual CreditScore')\n",
    "plt.plot(test_data.index, predicted_inverse, label='Predicted CreditScore')\n",
    "plt.title('CreditScore Forecast using Transformer')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('CreditScore')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
